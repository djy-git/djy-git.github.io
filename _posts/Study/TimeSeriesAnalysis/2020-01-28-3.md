---
title: 3. ARIMA models - ACF, PACF
tags: Study_TimeSeriesAnalysis
aside:
  toc: true
---

# Remarks
본 글은 [한양대학교 이기천 교수님의 시계열분석 강의 3강](https://youtu.be/QVUEpSofpU0)을 정리한 글입니다.

<!--more-->

---

이전 강의까지 trend를 찾아내는 몇 가지 방법들을 배웠다. <br>
찾아낸 trend를 제거하면 residual이 남게 되는데, 이번 강의부터는 residual을 modeling하는 방법에 대해 배운다. <br>


# 1. Autoregressive model
## 1) AR(1)
$$
\begin{equation}
\begin{aligned}
    x_t &= \phi x_{t-1} + a_t + \mu \\
    &= \phi(\phi x_{t-2} + a_{t-1} + \mu) + a_t + \mu \\
    &= \ ... \\
    &= a_t + \phi a_{t-1} + \phi^2 a_{t-2} + \cdots \\
    &\ \quad \mu + \phi \mu + \phi^2 \mu + \cdots \\
    &= \phi^m x_{t-m} + \phi^{m-1} a_{t-(m-1)} + \cdots + a_t + (\phi^{m-1} + \cdots + 1) \mu \\
    &\approx a_t + \cdots + \phi^{m-1} a_{t-(m-1)} + (1 + \cdots + \phi^{m-1}) \mu \quad \text{ if } \mid \phi \mid < 1 \text{ and } m \text{ is sufficiently large} \\
    &\approx a_t + \cdots + \phi^{m-1} a_{t-(m-1)} + \frac{\mu}{1 - \phi}
\end{aligned}
\end{equation}
$$

### - Expectation
$$
\begin{equation}
\begin{aligned}
    E(x_t) &= E(\phi x_{t-1} + a_t + \mu) \\
    &= \phi E(x_{t-1}) + \mu \quad \text{ if } \ E(x_t) = E(x_{t-1}) \\
    E(x_t) &= \frac{\mu}{1-\phi}
\end{aligned}
\end{equation}
$$

즉, $\mid \phi \mid < 1$ 조건이 주어졌을 때, 그리고 $E(x_t)$와 $E(x_t) = E(x_{t-1}$ 조건이 주어졌을 때의 $E(x_t)$가 $\frac{\mu}{1 - \phi}$로 동일하다. <br>

### - Variance
$$
\begin{equation}
\begin{aligned}
    Var(x_t) &= Var(a_t + \cdots + \phi^{m-1} a_{t-(m-1)} + \frac{\mu}{1 - \phi}) \\
    &= Var(a_t) + \cdots + \phi^{2(m-1)} Var(a_{t-(m-1)}) \\
    &= \sigma^2 + \cdots + \phi^{2(m-1)}\sigma^2 \\
    &= \frac{\sigma^2}{1 - \phi^2} \\
\end{aligned}
\end{equation}
$$

Expectation과 마찬가지로, $\mid \phi \mid < 1$ 조건에서 $Var(x_t) = Var(x_{t-1})$ 조건이 주어진 경우와 동일한 결과를 보인다. <br>

### - Covariance
$Cov(x_t, a_{t+1}) = 0$ <br>
왜냐하면 $x_t$는 $a_t, a_{t-1}, \cdots$ 들로 구성되지만, $a_{t-h}$는 $a_{t+1}$과 독립이기 때문에 covariance가 0이다. <br>

## 2) Causality
$x_t = f(a_t, a_{t-1}, \cdots)$ 인 system을 **causal** system이라고 한다. <br>
즉, 현재의 observation이 현재의 noise와 이전의 noise들에 의해서 표현되는 system을 causal system이라고 부른다. <br>
Observation $x_t$를 random variable $a_t$들로 나타낸다면, 통계학적으로 여러가지를 말할 수 있게된다. (confidence interval 등)


- **Causal ARMA model** <br>
$x_t = \theta_0 a_t - \theta_1 a_{t-1} - \cdots$ &emsp; ($\theta_0 = 1$) <br>
$\sum_{j=0}^\infty \mid \theta_j \mid < \infty$ (bounded) <br>
<br>
AR(1)이 causal ARMA model이 되기 위해선, $\mid \phi \mid < 1$ 조건이 필요하다. (stationary 조건과 동일) <br>
<br>
ex) $x_t = 2x_{t-1} - a_t$ 는 causal system이 아니다. <br>
$$
\begin{equation}
\begin{aligned}
    x_t &= 2x_{t-1} - a_t \\
    x_{t-1} &= \frac{1}{2}x_t + \frac{a_t}{2} \\
    &= \frac{a_t}{2} + \frac{a_{t+1}}{2^2} + \frac{x_{t+1}}{2^2} \\
    &= \frac{a_t}{2} + \frac{a_{t+1}}{2^2} + \frac{a_{t+2}}{2^3} + \cdots
\end{aligned}
\end{equation}
$$
<br> 혹은, <br>
$$
\begin{equation}
\begin{aligned}
    x_t &= 2x_{t-1} - a_t \\
    &= 2^m x_{t-m} + 2^{m-1}a_{t-(m-1)} + \cdots + 2 a_{t-1} + a_t
\end{aligned}
\end{equation}
$$
<br>
Stationary하지만, causal system은 아니다.

- **Stationary and Causal system** <br>
우리가 분석할 대상은 stationary 하면서도 causal한 system이다. <br>
이를 위해 causal model을 가정한다. ($x_t$ and $a_{t+1}$ are not correlated)<br>

## 3) Beyond AR(1)
### - AR(1)
$$
\begin{equation}
\begin{aligned}
    x_t &= \phi x_{t-1} + a_t + \mu   \quad \cdots \text{ constant } \mu \text{ can be removed by centering} \\
    &= \phi Bx_t + a_t  + \mu \\
    x_t - \phi Bx_t &= a_t  + \mu \\
    (1 - \phi B)x_t &= a_t  + \mu \\
    x_t &= \frac{1}{1 - \phi B} (a_t  + \mu ) \quad \cdots \text{ causal expression} \\
    &= (1 + \phi B + \phi^2 B^2 + \cdots) (a_t  + \mu ) \quad \text{ if } \ \mid \phi \mid < 1 \\
    &= a_t + \phi a_{t-1} + \phi^2 a_{t-2} + \cdots + \\
    &\ \quad \ \mu + \phi \mu + \phi^2 \mu + \cdots
\end{aligned}
\end{equation}
$$

### - AR(2)
$$
\begin{equation}
\begin{aligned}
    x_t &= \phi_1 x_{t-1} + \phi_2 x_{t-2} + a_t + \mu   \quad \cdots \text{ constant } \mu \text{ can be removed by centering} \\
    &= \phi_1 Bx_t + \phi_2 B^2x_t + a_t + \mu \\
    x_t - \phi_1 Bx_t - \phi_2 B^2x_t &= a_t  + \mu \\
    (1 - \phi_1 B - \phi_2 B^2)x_t &= a_t  + \mu \\
    (1 - \alpha_1B)(1 - \alpha_2B)x_t &= a_t + \mu \\
    x_t &= \frac{1}{(1 - \alpha_1B)(1 - \alpha_2B)} (a_t  + \mu ) \quad \cdots \text{ causal expression} \\
    &= \frac{1}{1 - \alpha_1B} \frac{1}{1 - \alpha_2B}(a_t +\mu) \\
    &= (1 + \alpha_1 B + \alpha_1^2 B^2 + \cdots) (1 + \alpha_2 B + \alpha_2^2 B^2 + \cdots) (a_t  + \mu ) \quad \text{ if } \ \mid \alpha_1 \mid < 1 \text{ and } \mid \alpha_2 \mid < 1 \\
    &= (1 + (\alpha_1 + \alpha_2)B + (\alpha_1^2 + \alpha_1 \alpha_2 + \alpha_2^2)B^2 + \cdots)(a_t + \mu) \\
    &= a_t + \beta_1 a_{t-1} + \beta_2 a_{t-2} + \cdots + \\
    &\ \quad \ \mu + \gamma_1 \mu + \gamma_2 \mu + \cdots
\end{aligned}
\end{equation}
$$

한편, 등비급수로 표현(invertible)되기 위한 조건은 다음과 같이 $\phi$에 대한 식으로 변경될 수 있다. <br>
$$
\begin{equation}
\begin{aligned}
  &\ \mid \alpha_1 \mid < 1 \text{ and } \mid \alpha_2 \mid < 1 \\
  &\Leftrightarrow \ \phi_1 + \phi_2 < 1 \text{ and } \phi_2 - \phi_1 < 1 \text{ and } \mid \phi_2 \mid < 1
\end{aligned}
\end{equation}
$$

### - AR(3)
$$
\begin{equation}
\begin{aligned}
    x_t &= \phi_1 x_{t-1} + \phi_2 x_{t-2} + \phi_3 x_{t-3} + a_t + \mu   \quad \cdots \text{ constant } \mu \text{ can be removed by centering} \\
    &= \phi_1 Bx_t + \phi_2 B^2x_t + \phi_3 B^3x_t + a_t + \mu \\
    x_t - \phi_1 Bx_t - \phi_2 B^2x_t - \phi_3 B^3x_t &= a_t  + \mu \\
    (1 - \phi_1 B - \phi_2 B^2 - \phi_3 B^3)x_t &= a_t  + \mu \\
    (1 - \alpha_1B)(1 - \alpha_2B)(1 - \alpha_3B)x_t &= a_t + \mu \\
\end{aligned}
\end{equation}
$$
<br>

$$
\begin{equation}
\begin{aligned}
    x_t &= \frac{1}{(1 - \alpha_1B)(1 - \alpha_2B)(1 - \alpha_3B)} (a_t  + \mu ) \quad \cdots \text{ causal expression} \\
    &= \frac{1}{1 - \alpha_1B} \frac{1}{1 - \alpha_2B} \frac{1}{1 - \alpha_3B}(a_t +\mu) \\
    &= (1 + \alpha_1 B + \alpha_1^2 B^2 + \cdots) (1 + \alpha_2 B + \alpha_2^2 B^2 + \cdots) (1 + \alpha_3 B + \alpha_3^2 B^2 + \cdots) (a_t  + \mu ) \quad \text{ if } \ \mid \alpha_1 \mid < 1 \text{ and } \mid \alpha_2 \mid < 1 \text{ and } \mid \alpha_3 \mid < 1 \\
    &= (1 + (\alpha_1 + \alpha_2 + \alpha_3)B + (\alpha_1^2 + \alpha_2^2 + \alpha_3^2 + \alpha_1 \alpha_2 + \alpha_2 \alpha_3 + \alpha_3 \alpha_1)B^2 + \cdots)(a_t + \mu) \\
    &= a_t + \beta_1 a_{t-1} + \beta_2 a_{t-2} + \cdots + \\
    &\ \quad \ \mu + \gamma_1 \mu + \gamma_2 \mu + \cdots
\end{aligned}
\end{equation}
$$

지금까지 한 것은 AR(1)부터 expectation, variance를 구하고 stationary, invertible 하게 표현할 수 있는 조건을 찾아내었다. <br>
그리고 recursive하게 적어 causal하게 표현될 수 있는 조건을 찾았다. (모두 동일) <br>
AR(2), AR(3) 역시 AR(1)과 마찬가지로 유사한 식으로 표현된다는 것을 확인하였다. <br>

**ex)** AR(2): $x_t = x_{t-1} - 0.89 x_{t-2} + a_t$ <br>
1. $(1 - B + 0.89 B^2)x_t = a_t$ <br>
2. $(1 - (0.5 + 0.8i))(1 + (0.5 - 0.8i))x_t = a_t$ <br>
3. $x_t = a_t + \psi_1 a_{t-1} + \psi_2 a_{t-2} + \cdots$ &emsp; ($\psi_1 = \alpha_1 + \alpha_2 = 1$, $\psi_2 = \alpha_1^2 + \alpha_2^2 + \alpha_1 \alpha_2 = 0.11$) <br>
⇒ $x_t$ is stationary and causal <br>
이와 같이 AR model에서 coefficient가 주어진 경우, causal expression에서 coefficient를 구할 수 있고 $x_t$의 stationarity와 causality도 알 수 있다. <br>


## 4) Appropriate order of AR
주어진 time series에 적절한 model을 정하기 위해, autocovariance / autocorrelation function $\gamma_x(h)$ 혹은 $\rho_x(h)$를 이용한다. <br>


# 2. Yule-Walker equation
**For example, how do we relate $\gamma_x(h)$ or $\rho_x(h)$ to AR(2)?** <br>
$\phi$를 예측하기 위해 $\gamma_x(h)$, $\rho_x(h)$이 model과 어떻게 연관되어 있는지 알려주는 식이 **Yule-Walker equation**이다. <br>

- **AR(2)** <br>
$$
\begin{equation}
\begin{aligned}
    x_t &= \phi_1 x_{t-1} + \phi_2 x_{t-2} + a_t + \mu \\
    x_t x_{t-h} &= \phi_1 x_{t-1} x_{t-h} + \phi_2 x_{t-2} x_{t-h} + a_t x_{t-h} + \mu x_{t-h} \quad \cdots \text{ multiply } x_{t-h} \\
    E(x_t x_{t-h}) &= E(\phi_1 x_{t-1} x_{t-h} + \phi_2 x_{t-2} x_{t-h} + a_t x_{t-h} + \mu x_{t-h}) \\
    &= \phi_1 E(x_{t-1} x_{t-h}) + \phi_2 E(x_{t-2} x_{t-h}) + E(a_t x_{t-h}) + \mu E(x_{t-h}) \\
    \\
    \text{if $h = 0$,} \\
    E(x_t x_{t-0}) &= E(x_t^2) = Var(x_t) = \gamma_x(0) \quad \cdots \text{ assume } E(x_t) = 0 \\
    &= \phi_1 E(x_{t-1} x_{t}) + \phi_2 E(x_{t-2} x_{t}) + E(a_t x_t) + \mu E(x_t) \\
    &= \phi_1 \gamma_x(1) + \phi_2 \gamma_x(2) + \sigma^2 \quad \cdots \ E(a_t x_t) = Cov(a_t, x_t) = Cov(a_t, a_t + \psi_1 a_{t-1} + \cdots) = Var(a_t) \\
    \\
    \text{if $h = 1$,} \\
    E(x_t x_{t-1}) &= Cov(x_t, x_{t-1}) = \gamma_x(1) \quad \cdots \text{ assume } E(x_t) = 0 \\
    &= \phi_1 E(x_{t-1} x_{t-1}) + \phi_2 E(x_{t-2} x_{t-1}) + E(a_t x_{t-1}) + \mu E(x_{t-1}) \\
    &= \phi_1 \gamma_x(0) + \phi_2 \gamma_x(1) \quad \cdots \ E(a_t x_{t-1}) = Cov(a_t, x_{t-1}) = Cov(a_t, a_{t-1} + \psi_1 a_{t-2} + \cdots) = 0 \\
    \\
    \text{if $h = 2$,} \\
    E(x_t x_{t-2}) &= Cov(x_t, x_{t-2}) = \gamma_x(2) \quad \cdots \text{ assume } E(x_t) = 0 \\
    &= \phi_1 E(x_{t-1} x_{t-2}) + \phi_2 E(x_{t-2} x_{t-2}) + E(a_t x_{t-2}) + \mu E(x_{t-2}) \\
    &= \phi_1 \gamma_x(1) + \phi_2 \gamma_x(0) \quad \cdots \ E(a_t x_{t-2}) = Cov(a_t, x_{t-2}) = Cov(a_t, a_{t-2}+ \psi_1 a_{t-3} + \cdots) = 0 \\
    \\
    \text{for $h > 2$,} \\
    E(x_t x_{t-h}) &= \gamma_x(h) \\
    \gamma_x(h) &= \phi_1 \gamma_x(h-1) + \phi_2 \gamma_x(h-2)
\end{aligned}
\end{equation}
$$

## 1) Yule-Walker equation
$$
 \gamma_x(h)-\phi_1 \gamma_x(h-1) - \phi_2 \gamma_x(h-2) =
    \begin{cases}
      \sigma^2 & \quad \text{if } h = 0 \\
      0  & \quad \text{if } h \geq 1 \\
    \end{cases}
$$

- **Autocorrelation** <br>
$\rho_x(h) = \frac{\gamma_x(h)}{\gamma_x(0)}, \rho_x(0) = 1$ <br>
$$
\begin{aligned}
 \rho_x(h) = 1 \quad &\text{if } h = 0 \\
 \rho_x(h)-\phi_1 \rho_x(h-1) - \phi_2 \rho_x(h-2) = 0 \quad &\text{if } h \geq 1
\end{aligned}
$$

## 2) Find $\phi$ from $\rho(h)$

$$
\begin{aligned}
    \text{if } h = 1, \quad \quad \quad \quad \quad \quad \quad \quad \quad \\
    \rho_x(1) - \phi_1 \rho_x(0) - \phi_2 \rho_x(1) &= 0 \\
    \rho_x(1) - \phi_1 - \phi_2 \rho_x(1) &= 0 \\
    \\
    \text{if } h = 2, \quad \quad \quad \quad \quad \quad \quad \quad \quad \\
    \rho_x(2) - \phi_1 \rho_x(1) - \phi_2 \rho_x(0) &= 0 \\
    \rho_x(2) - \phi_1 \rho_x(1) - \phi_2 &= 0 \\
\end{aligned}
$$

주어진 time series로부터 $\rho(h)$를 구할 수 있고, 이로부터 얼마든지 $\phi$를 계산해낼 수 있다. <br>

$$
\begin{cases}
  \rho_x(1) - \phi_1 - \phi_2 \rho_x(1) = 0 \\
  \rho_x(2) - \phi_1 \rho_x(1) - \phi_2 = 0 \\
\end{cases}
$$
<br>

**ex)** <br>
Observations: $x_1, \cdots x_{144}$ ($n=144$) <br>
Assume AR(2) model: $x_t = \phi_1 x_{t-1} + \phi_2 x_{t-2} + a_t$ (나중에 어떤 model이 좋은지 설명)<br>
**Estimate $\phi_1, \phi_2$**

1. **Compute $\hat \gamma(1), \hat \gamma(2)$** <br>
$$
\begin{aligned}
    \gamma(h) &= Cov(x_t, x_{t-h}) \\
    &= E[(x_t - \mu) (x_{t-h} - \mu)] \quad \cdots \ \mu \equiv E(x_t) \\
    \hat \gamma(h) &= \frac{1}{n-h} \sum_{t = h+1}^n (x_t - \bar x)(x_{t-h} - \bar x) \quad \cdots \ \bar x \equiv \frac{1}{n} \sum_t x_t
\end{aligned}
$$ <br>
2. 

---


asdasd
asdasd

asdasd

asdasd

asdasd

asdasd
